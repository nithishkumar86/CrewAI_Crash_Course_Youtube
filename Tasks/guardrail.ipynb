{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3bcaf13",
   "metadata": {},
   "source": [
    "## Tasks Guardrails\n",
    "\n",
    "\n",
    "Task guardrails provide a way to validate and transform task outputs before they are passed to the next task. This feature helps ensure data quality and provides feedback to agents when their output doesn’t meet specific criteria\n",
    "\n",
    "## CrewAI supports two types of guardrails:\n",
    "\n",
    "## 1. Function-based guardrails:\n",
    "\n",
    " Python functions with custom validation logic, giving you complete control over the validation process and ensuring reliable, deterministic results.\n",
    "\n",
    "\n",
    "## 2. LLM-based guardrails:\n",
    "\n",
    " String descriptions that use the agent’s LLM to validate outputs based on natural language criteria. These are ideal for complex or subjective validation requirements.\n",
    "\n",
    "\n",
    "\n",
    "it is in tuple format -> (Bool,Any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ac23a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, LLM,TaskOutput\n",
    "from pydantic import BaseModel\n",
    "from typing import Tuple,Any\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from crewai import Crew\n",
    "load_dotenv() \n",
    "\n",
    "\n",
    "llm = LLM(model=\"groq/llama-3.3-70b-versatile\",\n",
    "        verbose = True,\n",
    "        temperature = 0.2,\n",
    "        api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cf77327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_summary_length(task_output: TaskOutput)->Tuple[bool,Any]:\n",
    "    try:\n",
    "        print(\"Validating summary length\")\n",
    "        task_str_output = str(task_output)\n",
    "        total_words = len(task_str_output.split())\n",
    "\n",
    "        print(f\"Word count: {total_words}\")\n",
    "\n",
    "        if total_words > 200:\n",
    "            print(\"Summary exceeds 150 words\")\n",
    "            return (False, f\"Summary exceeds 150 words. Word count: {total_words}\")\n",
    "\n",
    "        if total_words == 0:\n",
    "            print(\"Summary is empty\")\n",
    "            return (False, \"Generated summary is empty.\")\n",
    "\n",
    "        print(\"Summary is valid\")\n",
    "        return (True, task_output)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Validation system error\")\n",
    "        return (False, f\"Validation system error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f30ed581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Task, Agent\n",
    "\n",
    "blog_agent = Agent(\n",
    "    role=\"Professional Blog Writer\",\n",
    "    goal=\"Write an engaging, informative blog post strictly in 200 words based on the user-provided topic.\",\n",
    "    backstory=(\n",
    "        \"You are an expert content writer specializing in high-quality, SEO-friendly blog posts. \"\n",
    "        \"You write clear, engaging, and structured content tailored to the given topic. \"\n",
    "        \"You strictly follow word count requirements and never exceed or fall short of the specified limit.\"\n",
    "    ),\n",
    "    verbose=True,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "blog_task = Task(\n",
    "    description=(\n",
    "        \"Write a well-structured blog post strictly in 200 words on the following topic:\\n\\n\"\n",
    "        \"Topic: {topic}\\n\\n\"\n",
    "        \"Instructions:\\n\"\n",
    "        \"- The blog must be exactly 200 words.\\n\"\n",
    "        \"- Use a clear introduction, body, and conclusion.\\n\"\n",
    "        \"- Keep the content engaging and informative.\\n\"\n",
    "        \"- Do not include headings or extra explanations.\\n\"\n",
    "        \"- Output only the blog content.\\n\"\n",
    "    ),\n",
    "    expected_output=\"A strictly 200-word blog post based on the provided topic.\",\n",
    "    agent=blog_agent,\n",
    "    guardrail=validate_summary_length,  # validates exactly 200 words\n",
    "    max_retries=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "424e4ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "    agents=[blog_agent],\n",
    "    tasks=[blog_task],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d63b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = crew.kickoff(inputs={\"topic\":\"AI in Automation\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86852f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d5f22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1230dd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class ResearchReport(BaseModel):\n",
    "    \"\"\"Represents a structured research report\"\"\"\n",
    "    title: str\n",
    "    summary: str\n",
    "    key_findings: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0119dde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Tuple, Any\n",
    "\n",
    "def validate_json_report(result: TaskOutput) -> Tuple[bool, Any]:\n",
    "    \"\"\"Ensures AI-generated output is valid JSON with required fields.\"\"\"\n",
    "    try:\n",
    "        # Parse JSON output\n",
    "        data = json.loads(result.pydantic.model_dump_json())\n",
    "\n",
    "        # Check required fields\n",
    "        if \"title\" not in data or \"summary\" not in data or \"key_findings\" not in data:\n",
    "            return (False, \"Missing required fields: title, summary, or key_findings.\")\n",
    "\n",
    "        return (True, result)  # JSON is valid\n",
    "    except json.JSONDecodeError:\n",
    "        return (False, \"Invalid JSON format. Please ensure correct syntax.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a28fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent\n",
    "\n",
    "# Create the AI Agent\n",
    "research_report_agent = Agent(\n",
    "    role=\"Research Analyst\",\n",
    "    goal=\"Generate structured JSON reports for research papers\",\n",
    "    backstory=\"You are an expert in technical writing and structured reporting.\",\n",
    "    verbose=False,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29dabf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Task\n",
    "\n",
    "research_report_task = Task(\n",
    "    description=\"Generate a structured research report in valid JSON format.\",\n",
    "    expected_output=\"A valid JSON object containing 'title', 'summary', and 'key_findings'.\",\n",
    "    agent=research_report_agent,\n",
    "    output_pydantic=ResearchReport,  # Ensures structured output\n",
    "    guardrail=validate_json_report,  # Validate output before passing to next step\n",
    "    max_retries=3  # Allow up to 3 retries if validation fails\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52d457e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew\n",
    "\n",
    "research_crew = Crew(\n",
    "    agents=[research_report_agent],\n",
    "    tasks=[research_report_task],\n",
    "    verbose=True  # Display execution details\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467faf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = research_crew.kickoff()\n",
    "\n",
    "# Display the validated JSON output\n",
    "print(\"Final Research Report:\", result.pydantic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d618ee79",
   "metadata": {},
   "source": [
    "## LLM-Based Guardrails (String Descriptions)\n",
    "\n",
    "Instead of writing custom validation functions, you can use string descriptions that leverage LLM-based validation. When you provide a string to the guardrail or guardrails parameter, CrewAI automatically creates an LLMGuardrail that uses the agent’s LLM to validate the output based on your description.\n",
    "Requirements:\n",
    "The task must have an agent assigned (the guardrail uses the agent’s LLM)\n",
    "Provide a clear, descriptive string explaining the validation criteria\n",
    "\n",
    "## Requirements:\n",
    "The task must have an agent assigned (the guardrail uses the agent’s LLM)\n",
    "Provide a clear, descriptive string explaining the validation criteria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e55d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "blog_agent = Agent(\n",
    "    role = \"Technology Blog Writer\",\n",
    "    goal = \"Create concise, engaging blog posts about technology topics in under 200 words\",\n",
    "    backstory = \"You are an experienced technology writer with a talent for making complex topics \"\n",
    "    \"accessible and engaging. You specialize in creating clear, well-structured content that \"\n",
    "    \"educates readers without overwhelming them. Your writing style is conversational yet informative, \"\n",
    "    \"and you excel at distilling key insights into digestible formats.\",\n",
    "    llm = llm,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "# Single LLM-based guardrail\n",
    "blog_task = Task(\n",
    "    description=\"Write an engaging blog post about the impact of artificial intelligence in education. \"\n",
    "    \"Focus on practical applications, benefits for students and teachers, and emerging trends. \"\n",
    "    \"Structure the content with clear sections using bullet points where appropriate to enhance readability.\",\n",
    "    expected_output=\"A well-structured blog post under 200 words that is accessible to general readers, \"\n",
    "    \"uses bullet points for key information, avoids technical jargon, and maintains an engaging, \"\n",
    "    \"conversational tone throughout.\",\n",
    "    agent=blog_agent,\n",
    "    guardrail=\"The blog post must be under 200 words, written in plain language without technical jargon, \"\n",
    "    \"and be easily understandable by readers with no technical background\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ea1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "    agents=[blog_agent],\n",
    "    tasks=[blog_task],\n",
    "    verbose= True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86dd8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(crew.kickoff())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b527d2c8",
   "metadata": {},
   "source": [
    "## Multiple Guardrails\n",
    "\n",
    "You can apply multiple guardrails to a task using the guardrails parameter. Multiple guardrails are executed sequentially, with each guardrail receiving the output from the previous one. This allows you to chain validation and transformation steps.\n",
    "\n",
    "## The guardrails parameter accepts:\n",
    "\n",
    "A list of guardrail functions or string descriptions\n",
    "A single guardrail function or string (same as guardrail)\n",
    "Note: If guardrails is provided, it takes precedence over guardrail. The guardrail parameter will be ignored when guardrails is set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5de685d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Any\n",
    "from crewai import TaskOutput, Task\n",
    "\n",
    "def validate_word_count(result: TaskOutput) -> Tuple[bool, Any]:\n",
    "    \"\"\"Validate word count is within limits.\"\"\"\n",
    "    word_count = len(result.raw.split())\n",
    "    if word_count < 100:\n",
    "        return (False, f\"Content too short: {word_count} words. Need at least 100 words.\")\n",
    "    if word_count > 500:\n",
    "        return (False, f\"Content too long: {word_count} words. Maximum is 500 words.\")\n",
    "    return (True, result.raw)\n",
    "\n",
    "def validate_no_profanity(result: TaskOutput) -> Tuple[bool, Any]:\n",
    "    \"\"\"Check for inappropriate language.\"\"\"\n",
    "    profanity_words = [\"badword1\", \"badword2\"]  # Example list\n",
    "    content_lower = result.raw.lower()\n",
    "    for word in profanity_words:\n",
    "        if word in content_lower:\n",
    "            return (False, f\"Inappropriate language detected: {word}\")\n",
    "    return (True, result.raw)\n",
    "\n",
    "def format_output(result: TaskOutput) -> Tuple[bool, Any]:\n",
    "    \"\"\"Format and clean the output.\"\"\"\n",
    "    formatted = result.raw.strip()\n",
    "    # Capitalize first letter\n",
    "    formatted = formatted[0].upper() + formatted[1:] if formatted else formatted\n",
    "    return (True, formatted)\n",
    "\n",
    "# Apply multiple guardrails sequentially\n",
    "blog_task = Task(\n",
    "    description=\"Write a blog post about AI\",\n",
    "    expected_output=\"A well-formatted blog post between 100-500 words\",\n",
    "    agent=blog_agent,\n",
    "    guardrails=[\n",
    "        validate_word_count,      # First: validate length\n",
    "        validate_no_profanity,    # Second: check content\n",
    "        format_output             # Third: format the result\n",
    "    ],\n",
    "    guardrail_max_retries=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c099a03",
   "metadata": {},
   "source": [
    "In this example, the guardrails execute in order:\n",
    "\n",
    "validate_word_count checks the word count\n",
    "\n",
    "validate_no_profanity checks for inappropriate language (using the output from step 1)\n",
    "\n",
    "format_output formats the final result (using the output from step 2)\n",
    "\n",
    "If any guardrail fails, the error is sent back to the agent, and the task is retried up to \n",
    "guardrail_max_retries times.\n",
    "\n",
    "Mixing function-based and LLM-based guardrails:\n",
    "\n",
    "You can combine both function-based and string-based guardrails in the same list:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba13c3f",
   "metadata": {},
   "source": [
    "## Mixing function-based and LLM-based guardrails:\n",
    "\n",
    "You can combine both function-based and string-based guardrails in the same list:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f3d6af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Any\n",
    "from crewai import TaskOutput, Task\n",
    "\n",
    "def validate_word_count(result: TaskOutput) -> Tuple[bool, Any]:\n",
    "    \"\"\"Validate word count is within limits.\"\"\"\n",
    "    word_count = len(result.raw.split())\n",
    "    if word_count < 100:\n",
    "        return (False, f\"Content too short: {word_count} words. Need at least 100 words.\")\n",
    "    if word_count > 500:\n",
    "        return (False, f\"Content too long: {word_count} words. Maximum is 500 words.\")\n",
    "    return (True, result.raw)\n",
    "\n",
    "# Mix function-based and LLM-based guardrails\n",
    "blog_task = Task(\n",
    "    description=\"Write a blog post about AI\",\n",
    "    expected_output=\"A well-formatted blog post between 100-500 words\",\n",
    "    agent=blog_agent,\n",
    "    guardrails=[\n",
    "        validate_word_count,  # Function-based: precise word count check\n",
    "        \"The content must be engaging and suitable for a general audience\",  # LLM-based: subjective quality check\n",
    "        \"The writing style should be clear, concise, and free of technical jargon\"  # LLM-based: style validation\n",
    "    ],\n",
    "    guardrail_max_retries=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf87be",
   "metadata": {},
   "source": [
    "## Guardrail Function Requirements\n",
    "\n",
    "Function Signature:\n",
    "\n",
    "Must accept exactly one parameter (the task output)\n",
    "\n",
    "Should return a tuple of (bool, Any)\n",
    "\n",
    "Type hints are recommended but optional\n",
    "\n",
    "Return Values:\n",
    "\n",
    "On success: it returns a tuple of (bool, Any). For example: (True, validated_result)\n",
    "\n",
    "On Failure: it returns a tuple of (bool, str). For example: (False, \"Error message explain the failure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a46998",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''andling Guardrail Results\n",
    "When a guardrail returns (False, error):\n",
    "The error is sent back to the agent\n",
    "The agent attempts to fix the issue\n",
    "The process repeats until:\n",
    "The guardrail returns (True, result)\n",
    "Maximum retries are reached (guardrail_max_retries)\n",
    "Example with retry handling:'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crewai-course (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
